### — 第41頁 —

訓練這樣的編碼器堆疊並不容易；BERT 採用「遮罩語言模型（masked language modeling, MLM）」技巧（見第 2 與第 11 章）。如圖 1-22，訓練時隨機遮住部分輸入，讓模型去預測；雖然困難，但能迫使 BERT 學到更精準的（中間）表示。  

預訓練模型的巨大利益在於：大部分學習早已完成。針對任務的微調通常計算需求較低、所需資料也較少。而且，BERT 類模型在幾乎所有步驟都會產生嵌入，使其不必微調也能作為高效的「特徵抽取器」。  

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-22：以 MLM 方式訓練 BERT。

此架構與訓練程序，使 BERT 與同系架構在「表徵脈絡化語言」方面極其強大。BERT 類模型常用於「遷移學習（transfer learning）」：先以語言建模（language modeling）在大規模語料上預訓練，再針對特定任務做微調。例如，先在整個維基百科上預訓練，讓模型理解語義與脈絡；如圖 1-23，再把預訓練好的模型微調到特定任務（如文字分類）。  

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-23：BERT 先在大型語料以 MLM 預訓練，再微調到下游任務（分類、命名實體辨識、語句同義判定等）。  

### — 第42頁 —

僅編碼器的模型（如 BERT）會在本書多處出現。多年來，它們一直且仍被廣泛用於常見任務，包括分類（第 4 章）、分群（第 5 章）、語意搜尋（第 8 章）。  

全書中，我們把僅編碼器模型稱為「表徵模型（representation models）」，以區分僅解碼器（decoder-only）模型——我們稱之為「生成模型（generative models）」。需注意，兩者的差別不只在底層架構與運作方式，更在於用途：++表徵模型主要用於「表徵語言」，例如產生嵌入，通常不生成文字；生成模型主要「生成文字」，通常不是為生成嵌入而訓練++。  

在多數插圖中，我們也會以配色加以區別：表徵模型以青綠色（teal）呈現，並附上小向量圖示（表示它聚焦在向量與嵌入）；生成模型以粉色（pink）呈現，並附上小對話圖示（表示其生成能力）。  

### 小節標題：Generative Models: Decoder-Only Models\
生成模型：僅解碼器（decoder-only）模型

與 BERT 的「僅編碼器」相對，2018 年有人提出「僅解碼器」架構，專攻生成任務。該架構稱為「Generative Pre-trained Transformer（GPT，生成式預訓練轉換器）」，為區分後續版本，今多稱 GPT-1。如圖 1-24，它以++堆疊多個解碼器區塊的方式構成，與 BERT 的「堆疊編碼器」相似++。  

GPT-1 訓練於 7,000 本書籍與 Common Crawl（大型網頁語料）之上，總參數約 1.17 億。一般而言，在其他條件不變時，參數越多常能顯著影響語言模型的能力與表現。因此我們很快看到更大的模型相繼問世：如圖 1-25，GPT-2 約 15 億參數，GPT-3 接著上看 1750 億參數。  

### — 第43頁 —

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-24：GPT-1 架構為「僅解碼器」，並移除了「編碼器注意力」區塊。

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-25：GPT 系列在每一次迭代中快速「長大」。  

### — 第44頁 —

這些「僅解碼器」的生成式模型，尤其是「更大」的模型，通常被稱為大型語言模型（LLMs）。稍後我們會說明，++本書中的「LLM」不僅包含生成模型（decoder-only），也包含表徵模型（encoder-only）++。  

作為序列到序列的機器，生成式 LLM 讀入文字並嘗試「自動補全（autocomplete）」後續內容。雖然自動補全很方便，但其真正威力在於把它「訓練成聊天機器人（chatbot）」。與其只是補完文字，如果能被訓練成「回答問題」呢？++透過「微調（fine-tuning）」這些模型，我們可得到能遵循指令的「指令（instruct）／聊天（chat）」模型++。  

如圖 1-26，這類模型可接受使用者查詢（prompt），並輸出「最可能接著該 prompt 的回應」。因此你會常聽到生成模型也被稱為「完成模型（completion models）」。  

生成模型的一個關鍵屬性是「上下文長度（context length）」或「上下文視窗（context window）」。它表示模型可處理的「最大 token 數」，如圖 1-27。上下文視窗越大，就越能把整份文件餵進模型。注意，因為模型是自回歸的，每當生成新 token，目前上下文長度就會增加。  

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-26：生成式 LLM 讀入輸入並嘗試「完成」它；在指令模型中，這不只是補完，而是試圖回答問題。

### — 第45頁 —

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-27：上下文長度是 LLM 可處理的最大上下文。  

### 小節標題：The Year of Generative AI\
生成式 AI 之年

LLM 對整個領域產生了巨大影響，讓許多人把 2023 年稱作「生成式 AI 之年」。當年 ChatGPT（GPT-3.5）問世、普及並佔據媒體版面。需要注意的是，當我們說「ChatGPT」，其實指的是「產品」，而非背後的單一模型；最初它由 GPT-3.5 驅動，之後也納入更強的變體，如 GPT-4。  

但 2023 年的舞台並非只有 GPT-3.5。一如圖 1-28 所示（僅為概覽，仍有許多模型未列入），開源與專有 LLM 都以驚人速度走入大眾視野。許多開源的「基礎（foundation/base）模型」可以再被微調以執行特定任務（例如遵循指令）。  

### — 第46頁 —

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-28：生成式 AI 之年的鳥瞰（仍有許多模型未列出）。  

除了廣受歡迎的 Transformer 架構外，也有新的有前景架構浮現，如 Mamba 與 RWKV；它們嘗試在維持 Transformer 等級表現的同時，帶來更多優勢（例如更大的上下文或更快的推論）。  

這些發展充分展現了此領域的演進，也烘托 2023 年對 AI 而言何其動盪。要跟上語言 AI 內外的眾多進展，幾乎用盡我們所有的時間與精力。  

因此，本書不僅關注「最新的 LLM」。我們將探索如何讓其他模型（如嵌入模型、僅編碼器模型、甚至詞袋模型）來強化與賦能 LLM。  

### — 第47頁 —

### 小節標題：The Moving Definition of a “Large Language Model”\
「大型語言模型」的流動定義

回顧近年的語言 AI 發展，我們看到：一般最常被稱為「大型語言模型」的是「生成式、僅解碼器（Transformer）模型」，尤其是「很大」者。然而，這樣的描述其實過於狹隘。  

如果我們做出一個與 GPT-3 能力相當、但參數縮小 10 倍的模型，它就不算「大型」語言模型了嗎？  

同樣地，若我們釋出一個和 GPT-4 一樣大、但只能精準做文字分類、沒有生成能力的模型，它是否仍然是「大型語言模型」？即便它主要不是「生成」，而是在「表徵文字」？  

這類定義的問題在於：它把有能力的模型排除在外。對一個模型取什麼名字，並不會改變它的行為。  

由於「大型語言模型」這個詞的含義會隨新模型問世而演進，我們想在本書中明確界定：「Large（大）」是任意的；今天覺得大的，明天可能覺得小。名稱很多、指涉相似。對我們而言，「大型語言模型」也可包含那些「不生成文字、且能在消費級硬體上運行」的模型。  

因此，除了涵蓋生成模型，本書也涵蓋「少於 10 億參數、且不生成文字」的模型。我們將展示如何把嵌入模型、表徵模型、甚至詞袋模型用來賦能 LLM。  

### 小節標題：The Training Paradigm of Large Language Models\
大型語言模型的訓練範式

傳統機器學習通常是為特定任務（如分類）訓練一個模型，我們可以視為「一步驟」流程（圖 1-29）。  

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-29：傳統機器學習多為單步：針對特定任務（分類或回歸）直接訓練模型。  

### — 48頁 —

打造 LLM 則通常至少包含兩個步驟：  

步驟一：Language modeling（語言建模；也稱預訓練 pretraining）\
第一步耗費絕大多數的運算與時間。++模型在大量網路文本上訓練，學會文法、脈絡與語言模式++。這個廣泛的訓練階段，目標尚不超出「預測下一個詞」。此時得到的模型常被稱為「基礎（foundation/base）模型」；這些模型一般尚不會「遵循指令」。  

步驟二：Fine-tuning（微調；有時稱後訓練 post-training）\
第二步將第一步得到的模型，++針對較窄的任務進一步訓練，讓 LLM 能適應特定任務或展現期望行為++。例如可以把一個基礎模型微調成在某個分類任務表現優良，或能遵循指令。這能節省大量資源，因為預訓練代價高昂，且常需要一般個人或組織難以負擔的資料與算力。例如，Llama 2 的訓練資料規模約 2 兆 tokens；想像要多少計算！第 12 章我們將介紹多種把基礎模型微調到你自家資料的方法。  

凡是經歷過第一步（預訓練）的模型，我們都視作「預訓練模型（pretrained model）」，包含後續微調過的變體。這個兩步驟訓練流程如圖 1-30。  

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-30：相較傳統 ML，LLM 的訓練採「多步驟」流程：先預訓練，再針對任務微調（可加入更多對齊步驟）。  

另可加入更多微調步驟，進一步把模型對齊使用者偏好（偏好/對齊/人類回饋強化學習等，見第 12 章）。  

### — 第49頁 —

### 小節標題：Large Language Model Applications: What Makes Them So Useful?\
LLM 應用：為何如此實用？

LLM 的本質，讓它適合廣泛任務。搭配文字生成與提示（prompting），幾乎彷彿「想像力就是極限」。以下舉幾個常見任務與技巧：  

- 辨識顧客評論是正向或負向\
   這是監督式分類（supervised classification），可用僅編碼器與僅解碼器模型來處理；可以用預訓練模型（第 4 章），或進行微調（第 11 章）。  

- 建立系統以找出客服 tickets 中的共通主題\
   這是「無監督分類（unsupervised classification）」——++沒有預先定義的標籤++。我們可用僅編碼器模型完成分群/主題歸納，再用僅解碼器模型為主題命名（第 5 章）。  

- 建置檢索與查看相關文件的系統\
   LLM 系統的一大重點是能外掛外部資訊資源。透過語意搜尋（semantic search），我們可打造讓 LLM 更易存取與使用資訊的系統（第 8 章）。想更進一步，可建立或微調自家嵌入模型（第 12 章）。  

- 建構能使用外部資源（工具與文件）的 LLM 聊天機器人\
   這是多種技術的組合，展現 LLM 真正的威力來自「其它組件」。例如提示工程（prompt engineering，第 6 章）、檢索增強生成（RAG，第 8 章）、以及對 LLM 的微調（第 12 章）——這些都是 LLM 拼圖的關鍵片段。  

- 打造能根據冰箱內食材照片來寫食譜的 LLM\
   這是「多模態（multimodal）」任務：LLM 接受影像並據此推理（第 9 章）。LLM 正被拓展到其他模態，如視覺，開啟眾多有趣的應用。  

LLM 應用的開發極具成就感，部分邊界就來自你的想像。隨著模型愈趨精準，把它們用在實務或創作（例如角色扮演、寫兒童故事）只會越來越有趣。  

### — 第50頁 —

### 小節標題：Responsible LLM Development and Usage\
負責任的 LLM 發展與使用

LLM 的影響已經、而且很可能持續重大，因其廣泛採用。在探索 LLM 驚人能力的同時，我們務必把社會與倫理層面的影響放在心上。以下幾點至關重要：  

- 偏見與公平（Bias and fairness）\
   LLM 在大量資料上訓練，而這些資料可能含有偏見。模型可能學得並再現、甚至放大偏見。由於訓練資料很少公開，我們往往無從得知其中可能含有哪些偏誤，除非實際試用與評估。  

- 透明度與問責（Transparency and accountability）\
   由於 LLM 的能力驚人，有時難以分辨你是與人還是與 LLM 對話。因此在與人互動時使用 LLM，若沒有「人類在迴路（human in the loop）」，可能引發意想不到的後果。例如應用於醫療領域的 LLM 系統，可能會被視作醫療器材而受到法規監管。  

- 生成有害內容（Generating harmful content）\
   LLM 並不必然產生「真確」內容，卻可能信心十足地輸出錯誤文字。此外，它可被用來生成假新聞、文章與其他誤導性資訊。  

- 智慧財產權（Intellectual property）\
   LLM 的輸出是你的智慧財產，還是模型開發者的？若輸出與訓練資料中的某段文字相似，該智慧財產屬於原作者嗎？在無法存取訓練資料的情況下，難以釐清何時有版權內容被模型使用。  

- 法規（Regulation）\
   由於 LLM 的巨大影響，政府已開始規範其商業應用。例如歐盟的《AI 法案（EU AI Act）》即對包括 LLM 在內的基礎模型之開發與部署進行規範。  

在你開發與使用 LLM 的過程中，我們強調倫理思考的重要性，並鼓勵你深入了解 AI 系統的安全且負責任的使用。  

### 小節標題：Limited Resources Are All You Need\
「有限」資源也能起步

我們前面數次提到的「算力資源」，多半指你系統可用的 GPU。強力的 GPU（顯示卡）能使 LLM 的訓練與使用更有效率、也更快速。  

### — 第51頁 —

在選擇 GPU 時，一個重要構面是「VRAM（video RAM，顯示記憶體）」容量；它就是你 GPU 上可用的記憶體空間。實務上，VRAM 越多越好——因為一些模型若 VRAM 不足，根本無法啟用。  

由於訓練與微調 LLM 在 GPU 上的成本昂貴，缺乏強力 GPU 的人常被戲稱為「GPU-poor」。這反映了為訓練巨大模型而進行的「算力之戰」。以 Llama 2 家族為例，Meta 使用的是 A100-80GB GPU。若假設租用一張這樣的 GPU 每小時 1.50 美元，整體成本將超過 500 萬美元。  

可惜沒有一條公式能精準預測跑某個模型需要多少 VRAM；它取決於模型架構與大小、壓縮技術、上下文大小、以及執行模型的後端等。  

本書面向「GPU-poor」的讀者！我們將使用那些不需要最昂貴 GPU 或大預算也能運行的模型。為此，我們把全部程式碼做成 Google Colab 筆記本。寫作時，免費版 Colab 通常提供一張 16GB VRAM 的 T4 GPU——這也是我們建議的最低 VRAM。  

### 小節標題：Interfacing with Large Language Models\
與大型語言模型互動

學會如何和 LLM 互動，不僅是使用它們的必要條件，也是理解其內在運作的關鍵。隨著領域迅速演進，圍繞 LLM 的溝通方式、方法與套件層出不窮。本書將探索最常見的作法，包含使用「專有（closed source）」與「公開可用（open）」的模型。  

### 小節標題：Proprietary, Private Models\
專有、私有模型

封閉源碼 LLM 指未向大眾公開其權重與完整架構的模型，由特定組織開發並把底層程式碼保密。例子有 OpenAI 的 GPT-4 與 Anthropic 的 Claude。這些專有模型通常背靠顯著的商業支持，並已整合於其服務中。  

### — 52頁 —

你可透過「API（Application Programming Interface，應用程式介面）」與這些模型互動，如圖 1-31。以 Python 使用 ChatGPT 時，即可透過 OpenAI 的套件與服務介接，而非直接存取模型本體。  

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-31：封閉源碼 LLM 以 API 介接；模型的細節（程式碼與架構）不對使用者開放。

專有模型的一大優點是：使用者不用擁有強力 GPU。模型提供者負責託管與執行，通常也能調度更多算力。你也不必具備模型託管與運行的專業，降低了入門門檻。此外，這些模型由於投入巨大，表現往往優於多數開源同儕。  

但缺點是：服務可能昂貴。提供者承擔模型託管的風險與成本，通常會收費。再者，因無法直接存取模型，你也就無法自行微調。最後，你的資料會與提供者共享，這在許多情境（如醫療病患資料）並不理想。    

### 小節標題：Open Models\
開放模型

開放 LLM 指與公眾共享權重與架構供使用的模型；多由特定組織開發，並常分享建立或在本機運行模型的程式碼——但授權（license）各異，未必都允許商業用途。例子包括 Cohere 的 Command R、Mistral 系列、Microsoft 的 Phi、以及 Meta 的 Llama 等。  

何謂真正的「開源」仍有爭論。例如有些公開釋出的模型帶有「限制商業用途」的授權；很多人認為這不算真正的 open-source（開源應不設此限制）。同樣地，模型的訓練資料與完整源碼也很少完全公開。  

### — 53頁 —

若你的硬體足夠強，可把這些模型下載到本機使用，如圖 1-32。

![⏰\_書籍\_Books.png.jpg](./—%20第41頁%20—-assets/⏰_書籍_Books.png.jpg)

圖 1-32：開源 LLM 由使用者本機託管；模型細節（程式碼與架構）對使用者開放。  

其主要優點是你完全掌控模型：不依賴外部 API、可自行微調、可處理敏感資料、過程透明，並有大型社群（如 Hugging Face）支援。缺點是需要更強的硬體，尤其在訓練或微調時；此外也需要一定的安裝與操作知識（本書將逐步介紹）。整體而言，我們傾向在可行時優先使用開源模型，因為它們提供了更大的自由度，讓我們能探索內部機制、在本機運行等。  

### 小節標題：Open Source Frameworks\
開源框架

相較封閉 LLM，開源 LLM 需要一些套件來運行。2023 年有許多不同的套件與框架問世，各有其與 LLM 互動與運用的方式。要在「數以百計、愈來愈多」的框架中取捨，稱不上愉快的體驗，你或許甚至會在本書中找不到你的「心頭好」。  

因此，我們不嘗試面面俱到，而是致力於提供一套穩固的基礎，幫你「善用 LLM」。期望你讀完本書後，能很快上手其他多數框架——因為它們運作方式其實高度相似。這份「直覺」不僅包含對 LLM 的理解，也包含如何用常見框架在實務中操作；有了直覺，遷移到其它工具就會容易許多。  

### — 第54頁 —

更具體地說，我們聚焦於「後端（backend）套件」，即沒有 GUI、專為在你的裝置上高效率載入與運行任意 LLM 而打造的工具，例如：llama.cpp、LangChain，以及許多框架的核心——Hugging Face Transformers。當然，有時你只想要一個「像 ChatGPT 一樣的本地界面」來使用在地 LLM——市面上也有不少優秀方案，例如 text-generation-webui、KoboldCpp、LM Studio 等。  

### 小節標題：Generating Your First Text\
生成你的第一段文字

使用語言模型的一個關鍵步驟是「選模型」。尋找與下載 LLM 的主要來源是「Hugging Face Hub」。Hugging Face 是著名 Transformers 套件的維護組織，這個套件多年來驅動了語言模型的發展；如其名，該套件建立在我們稍早提到的 transformer 架構之上。寫作時，該平台上已經有超過 80 萬個模型，涵蓋多種用途，從 LLM、電腦視覺，到音訊與表格資料應用；幾乎任何開源 LLM 都能在此找到。  

雖然本書將探索各式模型，先從一個生成式模型開始寫第一段程式碼吧！本書將經常使用「Phi-3-mini」作為生成模型主角，它相對較小（約 38 億參數），但表現不俗。由於體量小，它可在 VRAM 少於 8GB 的裝置上運行；若再做量化（quantization，一種壓縮技術；詳見第 7 與第 12 章），甚至可用不到 6GB VRAM。更棒的是，它採 MIT 授權，允許在商業情境中無限制使用！  

要記得，新的、更強的 LLM 不斷推出。為確保本書示例具有持久性，我們大多把程式寫成能「替換不同 LLM 也能運作」；此外，我們會在本書的倉庫中推薦其他模型供你嘗試。  

開始吧！當你使用一個 LLM，會載入兩個模型組件：  

### — 第55頁 —

- 生成模型本體（generative model）  

- 它的斷詞器（tokenizer）  

斷詞器負責把輸入文字切成 tokens，再餵給生成模型。你可以在 Hugging Face 找到模型與斷詞器，只要傳入對應的 ID 即可。這裡我們使用 "microsoft/Phi-3-mini-4k-instruct"。  

接著用 Transformers 來載入模型與斷詞器。以下假設你有 NVIDIA GPU（device_map="cuda"），若沒有，可改其它裝置；沒有本機 GPU 的話，也能使用我們在本書倉庫中準備的免費 Google Colab 筆記本。  

Python 程式碼（略同原文；保持語意）：  

- 匯入 AutoModelForCausalLM 與 AutoTokenizer  

- from_pretrained 載入 "microsoft/Phi-3-mini-4k-instruct"  

- 使用 transformers.pipeline 建立 "text-generation" 管線（pipeline）  

   - 重要參數：  

      - return_full_text=False：只回傳模型輸出，不連同提示。  

      - max_new_tokens：限制生成的最大 token 數，避免輸出過長。  

      - do_sample=False：不採樣，總是選取機率最高的下一 token；第 6 章會介紹能「喚起創意」的採樣參數。  

接著，我們以「請生成一個關於雞的有趣笑話」為例，將提示以「角色＋內容」的結構傳給管線並生成輸出：  

- messages = \[{"role": "user", "content": "Create a funny joke about chickens."}\]  

- output = generator(messages)  

- print(output\[0\]\["generated_text"\])  

範例輸出（原文示例）：\
Why don't chickens like to go to the gym? Because they can't crack the eggsistence of it!  

就這樣！本書生成的第一段文字，是一個還不錯的雞之笑話。  

### — 第56–57頁 —

### 小節標題：Summary\
小結

在本章，我們回顧了 LLM 對語言 AI 的革命性衝擊；它顯著改變了我們處理翻譯、分類、摘要等任務的方法。透過語言 AI 的近史綜覽，我們從簡單的詞袋表示一路談到使用神經網路的更複雜表徵。  

我們討論了「注意力機制」作為把脈絡編入模型的一大步，是 LLM 之所以強力的關鍵。我們也概述了使用該機制的兩大類模型：表徵模型（僅編碼器，如 BERT）與生成模型（僅解碼器，如 GPT 家族）。在本書中，兩類皆視為大型語言模型。  

整體而言，本章提供了語言 AI 版圖的總覽：含其應用、社會與倫理層面的意涵，以及運行這類模型所需的資源。我們以 Phi-3 生成了第一段文字作為收尾——它將在本書中反覆登場。  

在接下來兩章，你將學到更多底層過程。我們將從第 2 章的「斷詞（tokenization）」與「嵌入（embeddings）」開始——這兩者常被低估，卻是語言 AI 的關鍵元件；接著在第 3 章深入語言模型的內部，理解其生成文字的精確方式。  

（第25頁～第57頁翻譯完）